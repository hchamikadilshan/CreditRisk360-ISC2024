{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb278d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb3b2e",
   "metadata": {},
   "source": [
    "## 1- Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce53c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/fraud_detection_dataset.csv\"\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d70b9",
   "metadata": {},
   "source": [
    "## 2- Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7547817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27b45e",
   "metadata": {},
   "source": [
    "## 4- Converting Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03d17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date conversions\n",
    "data['account_open_date'] = pd.to_datetime(data['account_open_date'])\n",
    "data['earliest_credit_account'] = pd.to_datetime(data['earliest_credit_account'])\n",
    "data['recent_trade_activity'] = pd.to_datetime(data['recent_trade_activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559bc007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical conversions\n",
    "data['location'] = data['location'].astype('category')\n",
    "data['occupation'] = data['occupation'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02753cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean to 0,1 convention \n",
    "data['multiple_applications_short_time_period'] = data['multiple_applications_short_time_period'].astype(int)\n",
    "data['watchlist_blacklist_flag'] = data['watchlist_blacklist_flag'].astype(int)\n",
    "data['public_records_flag'] = data['public_records_flag'].astype(int)\n",
    "data['applications_submitted_during_odd_hours'] = data['applications_submitted_during_odd_hours'].astype(int)\n",
    "data['payment_methods_high_risk'] = data['payment_methods_high_risk'].astype(int)\n",
    "data['charge_off_status'] = data['charge_off_status'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da5bb41",
   "metadata": {},
   "source": [
    "## 3- Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363f274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unusual_submission_pattern       910\n",
      "number_of_delinquent_accounts    700\n",
      "avg_balance_last_12months        350\n",
      "fico_score                       210\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Summary of missing values in each column\n",
    "missing_summary = data.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b31cf",
   "metadata": {},
   "source": [
    "### 3.1 - `unusual_submission_pattern`\n",
    "- `unusual_submission_pattern` has 910 missing values. This is about 13% of the data. So if we remove those that would affect the dataset a lot. So we choose to impute this with some value by analyzing its relationship with other variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e68225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Visualizing categorical variables against 'unusual_submission_pattern'\n",
    "\n",
    "# Convert 'unusual_submission_pattern' to a string (optional but useful for visualization)\n",
    "data['unusual_submission_pattern_str'] = data['unusual_submission_pattern'].astype(str)\n",
    "\n",
    "features = ['multiple_applications_short_time_period', 'watchlist_blacklist_flag', 'public_records_flag','applications_submitted_during_odd_hours','payment_methods_high_risk']\n",
    "\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.countplot(data=data, x=feature, hue='unusual_submission_pattern_str')\n",
    "    plt.title(f'Relationship between {feature} and unusual_submission_pattern')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf92bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chi-Square Test for `multiple_applications_short_time_period` ,`watchlist_blacklist_flag` and `public_records_flag`\n",
    "for feature in features:\n",
    "    contingency_table = pd.crosstab(data[feature], data['unusual_submission_pattern_str'])\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    print(f\"Chi-square test for {feature}:\\n p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39384f4f",
   "metadata": {},
   "source": [
    "- According to the above analysis due to features `multiple_applications_short_time_period`, `watchlist_blacklist_flag`, and `public_records_flag`, indicated a significant chi-square test results, KNN imputation was chosen for handling missing values in the `unusual_submission_pattern` feature due to its ability to capture complex relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254e710",
   "metadata": {},
   "source": [
    "### 3.1.1 Using KNN to impute missing values for `unusual_submission_pattern`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d86809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution (counts):\n",
      "unusual_submission_pattern\n",
      "False    4822\n",
      "True     1268\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution (percentages):\n",
      "unusual_submission_pattern\n",
      "False    79.178982\n",
      "True     20.821018\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Feature distributions (counts):\n",
      "\n",
      "multiple_applications_short_time_period distribution (counts):\n",
      "multiple_applications_short_time_period\n",
      "0    5187\n",
      "1    1813\n",
      "Name: count, dtype: int64\n",
      "\n",
      "watchlist_blacklist_flag distribution (counts):\n",
      "watchlist_blacklist_flag\n",
      "0    6120\n",
      "1     880\n",
      "Name: count, dtype: int64\n",
      "\n",
      "public_records_flag distribution (counts):\n",
      "public_records_flag\n",
      "0    5587\n",
      "1    1413\n",
      "Name: count, dtype: int64\n",
      "\n",
      "applications_submitted_during_odd_hours distribution (counts):\n",
      "applications_submitted_during_odd_hours\n",
      "0    4800\n",
      "1    2200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "payment_methods_high_risk distribution (counts):\n",
      "payment_methods_high_risk\n",
      "0    5343\n",
      "1    1657\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature distributions (percentages):\n",
      "\n",
      "multiple_applications_short_time_period distribution (percentages):\n",
      "multiple_applications_short_time_period\n",
      "0    74.1\n",
      "1    25.9\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "watchlist_blacklist_flag distribution (percentages):\n",
      "watchlist_blacklist_flag\n",
      "0    87.428571\n",
      "1    12.571429\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "public_records_flag distribution (percentages):\n",
      "public_records_flag\n",
      "0    79.814286\n",
      "1    20.185714\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "applications_submitted_during_odd_hours distribution (percentages):\n",
      "applications_submitted_during_odd_hours\n",
      "0    68.571429\n",
      "1    31.428571\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "payment_methods_high_risk distribution (percentages):\n",
      "payment_methods_high_risk\n",
      "0    76.328571\n",
      "1    23.671429\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = ['multiple_applications_short_time_period', \n",
    "            'watchlist_blacklist_flag', \n",
    "            'public_records_flag', \n",
    "            'applications_submitted_during_odd_hours', \n",
    "            'payment_methods_high_risk']\n",
    "target = 'unusual_submission_pattern'\n",
    "# Check the distribution of the target variable\n",
    "target_counts = data['unusual_submission_pattern'].value_counts()\n",
    "target_percentages = data['unusual_submission_pattern'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Check the distribution of each feature\n",
    "feature_counts = {feature: data[feature].value_counts() for feature in features}\n",
    "feature_percentages = {feature: data[feature].value_counts(normalize=True) * 100 for feature in features}\n",
    "\n",
    "# Display the results\n",
    "print(\"Target distribution (counts):\")\n",
    "print(target_counts)\n",
    "print(\"\\nTarget distribution (percentages):\")\n",
    "print(target_percentages)\n",
    "\n",
    "print(\"\\nFeature distributions (counts):\")\n",
    "for feature in features:\n",
    "    print(f\"\\n{feature} distribution (counts):\")\n",
    "    print(feature_counts[feature])\n",
    "    \n",
    "print(\"\\nFeature distributions (percentages):\")\n",
    "for feature in features:\n",
    "    print(f\"\\n{feature} distribution (percentages):\")\n",
    "    print(feature_percentages[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69377c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "features = ['multiple_applications_short_time_period', \n",
    "            'watchlist_blacklist_flag', \n",
    "            'public_records_flag', \n",
    "            'applications_submitted_during_odd_hours', \n",
    "            'payment_methods_high_risk']\n",
    "target = 'unusual_submission_pattern'\n",
    "\n",
    "# Separate data with complete target values for validation\n",
    "data[target] = data[target].map({True: 1, False: 0})\n",
    "complete_data = data.dropna(subset=[target])\n",
    "\n",
    "# Split complete data for cross-validation\n",
    "train_data, valid_data = train_test_split(complete_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize lists to store mean squared errors for different K values\n",
    "k_values = range(1, 21)\n",
    "mae_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Set up KNN Imputer with the current K value\n",
    "    knn_imputer = KNNImputer(n_neighbors=k)\n",
    "    \n",
    "    # Impute the training data and transform both train and validation sets\n",
    "    train_imputed = knn_imputer.fit_transform(train_data[features + [target]])\n",
    "    valid_imputed = knn_imputer.transform(valid_data[features + [target]])\n",
    "    \n",
    "    # Convert back to DataFrame for analysis\n",
    "    train_imputed_df = pd.DataFrame(train_imputed, columns=features + [target])\n",
    "    valid_imputed_df = pd.DataFrame(valid_imputed, columns=features + [target])\n",
    "    \n",
    "    # Calculate MSE between the original and imputed target values in validation data\n",
    "    mae = mean_absolute_error(valid_data[target], valid_imputed_df[target])\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "# Find the best K with the lowest MSE\n",
    "best_k = k_values[mae_scores.index(min(mae_scores))]\n",
    "print(f\"Best K value: {best_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd59a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a larger k value range (e.g., from 2 to 10) and check accuracy\n",
    "k_values = range(2, 11)  # You can experiment with other ranges\n",
    "accuracy_scores = {k: [] for k in k_values}\n",
    "\n",
    "for k in k_values:\n",
    "    knn_imputer = KNNImputer(n_neighbors=k)\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for train_index, valid_index in kf.split(complete_data):\n",
    "        train_data, valid_data = complete_data.iloc[train_index], complete_data.iloc[valid_index]\n",
    "        \n",
    "        # Fit the imputer on training data and transform both sets\n",
    "        train_imputed = knn_imputer.fit_transform(train_data[features + [target]])\n",
    "        valid_imputed = knn_imputer.transform(valid_data[features + [target]])\n",
    "        \n",
    "        # Convert back to DataFrame for target comparison\n",
    "        valid_imputed_df = pd.DataFrame(valid_imputed, columns=features + [target])\n",
    "        \n",
    "        # Calculate accuracy of imputed vs. original target values\n",
    "        fold_accuracy = accuracy_score(valid_data[target], valid_imputed_df[target].round())\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "    \n",
    "    # Average accuracy across folds for this k\n",
    "    accuracy_scores[k] = np.mean(fold_accuracies)\n",
    "\n",
    "# Identify the best k value with highest accuracy\n",
    "best_k = max(accuracy_scores, key=accuracy_scores.get)\n",
    "print(f\"Best K value by accuracy: {best_k}, Accuracy: {accuracy_scores[best_k]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ccc62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target\n",
    "features = ['multiple_applications_short_time_period', \n",
    "            'watchlist_blacklist_flag', \n",
    "            'public_records_flag', \n",
    "            'applications_submitted_during_odd_hours', \n",
    "            'payment_methods_high_risk']\n",
    "target = 'unusual_submission_pattern'\n",
    "\n",
    "# Convert 'unusual_submission_pattern' to numerical (1 for True, 0 for False, NaN remains NaN)\n",
    "data[target] = data[target].map({True: 1, False: 0})\n",
    "\n",
    "# Select the rows where 'unusual_submission_pattern' is not NaN for fitting the imputer\n",
    "data_for_imputation = data[features + [target]]\n",
    "\n",
    "# Initialize the KNN Imputer with k=5 \n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Apply the KNN imputation\n",
    "data_imputed = knn_imputer.fit_transform(data_for_imputation)\n",
    "\n",
    "# Convert the imputed numpy array back to a DataFrame\n",
    "data_imputed_df = pd.DataFrame(data_imputed, columns=features + [target])\n",
    "\n",
    "# Replace the original 'unusual_submission_pattern' column with the imputed values\n",
    "data['unusual_submission_pattern'] = data_imputed_df[target]\n",
    "\n",
    "# Summary of missing values in each column\n",
    "missing_summary = data.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of the target variable\n",
    "sns.countplot(x='unusual_submission_pattern', data=data)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.show()\n",
    "\n",
    "# Check for imbalance in the features as well\n",
    "for feature in features:\n",
    "    sns.countplot(x=feature, data=data)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c79a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d8364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
